---
title: "Homework"
output:
  word_document: default
date: '2023-06-03'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# A. Data gathering and integration The first part is to get the data you will use. You may use anything that has not been used in an assignment or tutorial. It must have at least 100 data points and must include both numerical and categorial (or ordinal) variables. I recommend keeping this relatively straightforward because data cleaning can take a lot of time if you choose a large, messy dataset. Kaggle (https://www.kaggle.com/datasets) and the University of California at Irvine (UCI) (https://archive.ics.uci.edu/ml/index.php) maintain collections of datasets, some even telling you if they are good examples for testing specific machine learning techniques. You may also choose to join together more than one dataset, for example to merge data on health outcomes by US state with a dataset on food statistics per state. Merging data is not required and will earn you a bonus point in this step.

#Dataset Source : https://www.kaggle.com/datasets/arnabchaki/data-science-salaries-2023  

#Dataset Explaination :

#The Data Science Job Salaries Dataset is a collection of information related to salaries in the field of data science. It consists of 11 columns, each providing specific details about the data.

#The "work_year" column indicates the year in which the salary was paid, providing a temporal reference for the dataset. The "experience_level" column describes the level of experience the individual had in their job during that particular year. It helps to differentiate between junior, mid-level, and senior positions, or other categories based on experience.

#The "employment_type" column specifies the type of employment for the role, such as full-time, part-time, contract, or freelance. This information provides insights into the nature of the job and the terms of employment.

#The "job_title" column contains the role that the individual worked in during the year for which the salary information is provided. It helps to identify the specific job titles and positions within the data science field.

#The "salary" column represents the total gross salary amount paid to the employee during the specified year. This provides an indication of the financial compensation received by individuals in data science roles.

#The "salary_currency" column indicates the currency in which the salary was paid, following the ISO 4217 currency code. This information is crucial for understanding the currency context of the salary data.

#The "salaryinusd" column represents the salary amount converted into USD (United States Dollar). This column allows for better comparison and analysis of salaries across different countries or regions.

#The "employee_residence" column provides the primary country of residence for the employee during the work year, using the ISO 3166 country code. This information helps to identify the geographical distribution of data science professionals and their corresponding salaries.

#The "remote_ratio" column indicates the overall amount of work done remotely by the employee. It provides insights into the remote work culture and practices within the data science industry.

#The "company_location" column specifies the country of the employer's main office or contracting branch. It helps to understand the geographical distribution of companies hiring data science professionals.

#The "company_size" column represents the median number of people that worked for the company during the year. 

#This information provides an understanding of the company's scale and potentially its resources for compensating data science professionals. In summary, this dataset contains comprehensive information about salaries in the data science field, including temporal, experiential, employment, and geographical aspects. It enables analysis and exploration of the factors influencing salaries and their variations across different regions, job titles, experience levels, and company sizes.

#Rcode to perform basic dataset exploration

# B. Data Exploration Using data exploration to understand what is happening is important throughout the pipeline, and is not limited to this step. However, it is important to use some exploration early on to make sure you understand your data. You must at least consider the distributions of each variable and at least some of the relationships between pairs of variables.




```{r}
# Install and load the ggplot2 library
#install.packages("ggplot2")
library(ggplot2)

# Set the working directory to the folder containing the CSV file
setwd("/Users/devsendathamukkamala/Downloads")

# Read the data from the CSV file
data <- read.csv("ds_salaries.csv")

# Modify the display format of numbers
options(scipen = 999)

# Plot the distribution of salary_in_usd variable
ggplot(data, aes(x = salary_in_usd)) +
  geom_histogram(binwidth = 10000, fill = "steelblue") +
  labs(title = "Salary Distribution", x = "Salary (USD)", y = "Count") +
  theme_minimal()

# Plot the relationship between salary_in_usd and experience_level
ggplot(data, aes(x = experience_level, y = salary_in_usd, fill = experience_level)) +
  geom_boxplot() +
  labs(title = "Salary by Experience Level", x = "Experience Level", y = "Salary (USD)") +
  theme_minimal()

# Plot the relationship between salary_in_usd and employment_type
ggplot(data, aes(x = employment_type, y = salary_in_usd, fill = employment_type)) +
  geom_boxplot() +
  labs(title = "Salary by Employment Type", x = "Employment Type", y = "Salary (USD)") +
  theme_minimal()

# Plot the relationship between salary_in_usd and remote_ratio
ggplot(data, aes(x = remote_ratio, y = salary_in_usd)) +
  geom_point(color = "purple") +
  labs(title = "Salary vs. Remote Ratio", x = "Remote Ratio", y = "Salary (USD)") +
  theme_minimal()

# ... Continue exploring other variables and relationships as needed

```

#c. Data Cleaning
#Don’t forget – this can take a lot of the time of the whole process. Your cleaning process must ensure that there are no missing values and all outliers must be considered. It may be reasonable to just remove rows with missing values, however, if your data or small or that would change the distributions of the variables, that will not be adequate and you will need to consider other options, as discussed in the modules on cleaning. 

```{r}
# Check for missing values
missing_values <- sum(is.na(data))
print(paste("Number of missing values:", missing_values))

# Remove rows with missing values
data <- na.omit(data)

# Identify and handle outliers (e.g., using Tukey's method)
outliers <- boxplot.stats(data$salary_in_usd)$out
data <- data[!data$salary_in_usd %in% outliers, ]

# Save the cleaned data to a new CSV file
write.csv(data, "cleaned_ds_salaries.csv", row.names = FALSE)
```


#D. Data Preprocessing In some cases, preprocessing is absolutely necessary. It is rarely a bad idea. Make the case for what is and is not necessary given what you plan to do with the data. This could include making dummy variables, applying normalization, binning and/or smoothing, and other transformations (see course module).
```{r}
# Load required packages
library(dplyr)
library(RcppRoll)
library(ggplot2)

# Set the file paths
input_file <- "/Users/devsendathamukkamala/Downloads/ds_salaries.csv"
output_file <- "/Users/devsendathamukkamala/Downloads/ds_salaries_preprocessed.csv"

# Read the CSV file
data <- read.csv(input_file, stringsAsFactors = FALSE)

# Data preprocessing steps
# Remove unnecessary columns
data <- data %>% select(-salary_currency)

# Convert work_year and remote_ratio to numeric
data$work_year <- as.numeric(data$work_year)
data$remote_ratio <- as.numeric(data$remote_ratio)

# Create dummy variables for categorical columns
data <- data %>% 
  mutate(
    employment_type = ifelse(employment_type == "F", 1, 0),
    employee_residence = ifelse(employee_residence == "ES", 1, 0),
    company_location = ifelse(company_location == "ES", 1, 0)
  )

# Normalize the numeric columns (work_year, salary_in_usd)
data$work_year <- scale(data$work_year)
data$salary_in_usd <- scale(data$salary_in_usd)

# Binning and smoothing
# Binning work_year into categories
data$work_year_category <- cut(data$work_year, breaks = c(-Inf, -1, 0, 1, Inf), labels = c("Junior", "Mid-level", "Senior", "Executive"))

# Smooth salary_in_usd using a simple moving average with window size 3
data$salary_in_usd_smoothed <- RcppRoll::roll_mean(data$salary_in_usd, n = 3, fill = NA)

# Save the preprocessed data to a CSV file
write.csv(data, output_file, row.names = FALSE)

# Print the preprocessed data
print(data)

# Visualization
ggplot(data, aes(x = salary_in_usd, fill = work_year_category)) +
  geom_histogram(binwidth = 0.5, color = "white") +
  labs(x = "Salary (Standardized)", y = "Frequency") +
  ggtitle("Histogram of Standardized Salary") +
  theme_minimal() +
  theme(plot.background = element_rect(fill = "white"),
        panel.background = element_rect(fill = "white"),
        legend.position = "right",
        legend.title = element_blank(),
        legend.background = element_rect(fill = "white"),
        legend.box.background = element_rect(color = "black"),
        legend.text = element_text(color = "black"))

```


 
# e. Clustering Remove any labels from your data and use clustering to discover any built-in structure. Use an appropriate method to determine the number of clusters. If your data have labels, compare the clusters to those labels. If not, visualize the clustering results by making a PCA projection and coloring the points by cluster assignment. Note that PCA only works for numerical variables, so if your data have just a few categoricals, you may skip them. If there are many, use dummy variables or choose a different method for making a projection. One way is to make the distance matrix first (we covered a method for distance matrices using categorical variables in the clustering tutorial) and then apply PCA to that matrix. This is actually a way to calculate an MDS projection, a very popular method.

```{r}
# Load required packages
library(dplyr)
library(plotly)
library(factoextra)
library(FactoMineR)

# Read the data from CSV file
data <- read.csv("/Users/devsendathamukkamala/Downloads/ds_salaries_preprocessed.csv")

# Select numerical variables for clustering (exclude non-numeric or categorical variables)
numeric_vars <- select_if(data, is.numeric)

# Handle missing or infinite values
numeric_vars <- numeric_vars %>%
  mutate_all(~ifelse(is.na(.), mean(., na.rm = TRUE), .)) %>%  # Replace missing values with mean
  mutate_all(~ifelse(!is.finite(.), NA, .))  # Replace infinite values with NA

# Perform clustering using an appropriate method (e.g., k-means)
kmeans_model <- kmeans(numeric_vars, centers = 3)  # Example with 3 clusters

# Get cluster assignments for each data point
cluster_assignments <- kmeans_model$cluster

# Perform PCA on the numeric variables
pca_result <- PCA(numeric_vars, graph = FALSE)

# Create a data frame with PCA scores and cluster assignments
pca_data <- as.data.frame(pca_result$ind$coord)
pca_data$cluster <- as.factor(cluster_assignments)

# Visualize the clustering results using PCA projection
plot <- plot_ly(pca_data, x = ~Dim.1, y = ~Dim.2, color = ~cluster,
                colors = "Set1", type = "scatter", mode = "markers") %>%
  layout(xaxis = list(title = "PC1"), yaxis = list(title = "PC2"),
         title = "Clustering Results (PCA Projection)")

# Show the plot
plot

# Save the plot as an HTML file
htmlwidgets::saveWidget(plot, "clustering_results.html")

```

# f. Classification Use at least two classifiers to predict a label in your data. If a label was not provided with the data, use the clustering from the previous part. Follow the process for choosing the best parameters for your choice of classifier. Compare the accuracy of the two.

```{r}
# Load required libraries
library(caret)
library(randomForest)

# Read the dataset from CSV file
data <- read.csv("/Users/devsendathamukkamala/Downloads/ds_salaries.csv")

# Check the structure of the dataset
str(data)

# If label is not provided, perform clustering
if (!"label" %in% colnames(data)) {
  # Convert necessary columns to numeric
  numeric_cols <- c("work_year", "salary_in_usd")
  data[numeric_cols] <- lapply(data[numeric_cols], as.numeric)
  
  # Handle missing values
  data <- na.omit(data)  # Remove rows with any missing values
  
  # Perform clustering using k-means
  clusters <- kmeans(data[, c("work_year", "salary_in_usd")], centers = 3)
  
  # Add the cluster labels to the dataset
  data$label <- as.factor(clusters$cluster)
}

# Split the dataset into training and testing sets
set.seed(123)  # Set a seed for reproducibility
trainIndex <- createDataPartition(data$label, p = 0.7, list = FALSE)
trainData <- data[trainIndex, ]
testData <- data[-trainIndex, ]

# Define the features and the target variable
features <- c("work_year", "salary_in_usd")
target <- "label"

# Train the Decision Tree classifier
model_DT <- train(
  x = trainData[, features],
  y = trainData[, target],
  method = "rpart",
  trControl = trainControl(method = "cv", number = 10),
  tuneGrid = expand.grid(cp = seq(0.001, 0.1, by = 0.001))
)

# Train the Random Forest classifier
model_RF <- train(
  x = trainData[, features],
  y = trainData[, target],
  method = "rf",
  trControl = trainControl(method = "cv", number = 10),
  tuneGrid = expand.grid(mtry = seq(1, length(features), by = 1))
)

# Print the accuracy of the models
print(paste("Decision Tree accuracy:", model_DT$results$Accuracy[1]))
print(paste("Random Forest accuracy:", model_RF$results$Accuracy[1]))

```


```{r}
# Load required libraries
library(caret)
library(randomForest)
library(e1071)
library(pROC)
library(ggplot2)
library(gmodels)

# Read the dataset from CSV file
data <- read.csv("/Users/devsendathamukkamala/Downloads/ds_salaries.csv")

# Check the structure of the dataset
str(data)

# If label is not provided, perform clustering
if (!"label" %in% colnames(data)) {
  # Convert necessary columns to numeric
  numeric_cols <- c("work_year", "salary_in_usd")
  data[numeric_cols] <- lapply(data[numeric_cols], as.numeric)
  
  # Handle missing values
  data <- na.omit(data)  # Remove rows with any missing values
  
  # Perform clustering using k-means
  clusters <- kmeans(data[, c("work_year", "salary_in_usd")], centers = 3)
  
  # Add the cluster labels to the dataset
  data$label <- as.factor(clusters$cluster)
}

# Split the dataset into training and testing sets
set.seed(123)  # Set a seed for reproducibility
trainIndex <- createDataPartition(data$label, p = 0.7, list = FALSE)
trainData <- data[trainIndex, ]
testData <- data[-trainIndex, ]

# Define the features and the target variable
features <- c("work_year", "salary_in_usd")
target <- "label"

# Perform feature scaling
trainData_scaled <- scale(trainData[, features])
testData_scaled <- scale(testData[, features])

# Train the Decision Tree classifier
model_DT <- train(
  x = trainData_scaled,
  y = trainData[, target],
  method = "rpart",
  trControl = trainControl(method = "cv", number = 10),
  tuneGrid = expand.grid(cp = seq(0.001, 0.1, by = 0.001))
)

# Train the Random Forest classifier
model_RF <- train(
  x = trainData_scaled,
  y = trainData[, target],
  method = "rf",
  trControl = trainControl(method = "cv", number = 10),
  tuneGrid = expand.grid(mtry = seq(1, length(features), by = 1))
)

# Print the accuracy of the models
DT_accuracy <- model_DT$results$Accuracy[1]
RF_accuracy <- model_RF$results$Accuracy[1]
print(paste("Decision Tree accuracy:", DT_accuracy))
print(paste("Random Forest accuracy:", RF_accuracy))

# Plot feature importance for Random Forest
varImp_plot <- varImp(model_RF, scale = FALSE)
plot(varImp_plot, main = "Random Forest - Feature Importance")

# Predict labels using the trained models
DT_predictions <- predict(model_DT, testData_scaled)
RF_predictions <- predict(model_RF, testData_scaled)

# Create confusion matrix for Decision Tree
DT_confusion <- confusionMatrix(DT_predictions, testData[, target])
print("Decision Tree Confusion Matrix:")
print(DT_confusion)

# Create confusion matrix for Random Forest
RF_confusion <- confusionMatrix(RF_predictions, testData[, target])
print("Random Forest Confusion Matrix:")
print(RF_confusion)

# Plot ROC curve for Random Forest
RF_prob <- predict(model_RF, testData_scaled, type = "prob")
roc_obj <- roc(testData[, target], RF_prob[, "1"])
plot(roc_obj, main = "Random Forest - ROC Curve")

# Plot ROC curve for Random Forest
RF_prob <- predict(model_RF, testData_scaled, type = "prob")
roc_obj <- roc(testData[, target], RF_prob[, "1"])
plot(roc_obj, main = "Random Forest - ROC Curve")

# Display accuracy values on the plots
accuracy_text <- paste("Decision Tree Accuracy:", round(DT_accuracy, 2), "\n",
                       "Random Forest Accuracy:", round(RF_accuracy, 2))
text(0.5, 0.9, accuracy_text, cex = 1.2, font = 2, col = "blue")

# Display confusion matrix values
DT_cm_text <- paste("Decision Tree:\n",
                    "Accuracy:", round(DT_confusion$overall["Accuracy"], 2), "\n",
                    "Kappa:", round(DT_confusion$overall["Kappa"], 2))
RF_cm_text <- paste("Random Forest:\n",
                    "Accuracy:", round(RF_confusion$overall["Accuracy"], 2), "\n",
                    "Kappa:", round(RF_confusion$overall["Kappa"], 2))
text(0.15, 0.6, DT_cm_text, cex = 1.2, font = 2, col = "blue")
text(0.15, 0.4, RF_cm_text, cex = 1.2, font = 2, col = "blue")

# Print the accuracy of the models
DT_accuracy <- model_DT$results$Accuracy[1]
RF_accuracy <- model_RF$results$Accuracy[1]
print(paste("Decision Tree accuracy:", DT_accuracy))
print(paste("Random Forest accuracy:", RF_accuracy))

# Plotting the results
results <- data.frame(
  Model = c("Decision Tree", "Random Forest"),
  Accuracy = c(DT_accuracy, RF_accuracy)
)

# Bar plot for model accuracy
accuracy_plot <- ggplot(results, aes(x = Model, y = Accuracy, fill = Model)) +
  geom_bar(stat = "identity", width = 0.5) +
  labs(x = "Model", y = "Accuracy", title = "Model Accuracy Comparison") +
  scale_fill_manual(values = c("Decision Tree" = "blue", "Random Forest" = "green")) +
  theme_bw()
print(accuracy_plot)

# Explaination of the results
cat("The bar plot shows the comparison of model accuracies between the Decision Tree and Random Forest classifiers.\n",
    "The Decision Tree model achieved an accuracy of", DT_accuracy, "while the Random Forest model achieved an accuracy of", RF_accuracy, ".\n",
    "Based on this, the Random Forest model appears to perform slightly better than the Decision Tree model in terms of accuracy.\n")



```



EVALUATION

In this revised code, we perform the following steps:

Load the necessary libraries.
Read the dataset from the CSV file.
Perform clustering if the label is not provided.
Bin the classes into two groups.
Split the dataset into training and testing sets.
Define the features and the target variable.
Train the Random Forest classifier.
Predict labels using the trained model.
Convert the predicted labels and the target variable to factors with the same levels.
Create a confusion matrix using confusionMatrix().
Calculate precision and recall manually using the values from the confusion matrix.
Calculate the ROC curve using the roc() function from the pROC library.
Plot the ROC curve using plot().
The code will display the confusion matrix, precision, recall, and the ROC plot. The precision and recall provide insights into the classifier's performance beyond accuracy, while the ROC plot visually represents the classifier's trade-off between true positive rate and false positive rate.

```{r}
# Load required libraries
library(caret)
library(randomForest)
library(pROC)
library(ggplot2)

# Read the dataset from CSV file
data <- read.csv("/Users/devsendathamukkamala/Downloads/ds_salaries.csv")

# If label is not provided, perform clustering
if (!"label" %in% colnames(data)) {
  # Convert necessary columns to numeric
  numeric_cols <- c("work_year", "salary_in_usd")
  data[numeric_cols] <- lapply(data[numeric_cols], as.numeric)
  
  # Handle missing values
  data <- na.omit(data)  # Remove rows with any missing values
  
  # Perform clustering using k-means
  clusters <- kmeans(data[, c("work_year", "salary_in_usd")], centers = 3)
  
  # Add the cluster labels to the dataset
  data$label <- as.factor(clusters$cluster)
}

# Binning the classes into two groups
data$label <- ifelse(data$label == 1, "Group 1", "Group 2")

# Split the dataset into training and testing sets
set.seed(123)  # Set a seed for reproducibility
trainIndex <- createDataPartition(data$label, p = 0.7, list = FALSE)
trainData <- data[trainIndex, ]
testData <- data[-trainIndex, ]

# Define the features and the target variable
features <- c("work_year", "salary_in_usd")
target <- "label"

# Train the Random Forest classifier
model_RF <- train(
  x = trainData[, features],
  y = trainData[, target],
  method = "rf",
  trControl = trainControl(method = "cv", number = 10),
  tuneGrid = expand.grid(mtry = seq(1, length(features), by = 1))
)

# Predict labels using the trained model
RF_predictions <- predict(model_RF, testData[, features])

# Convert RF_predictions and testData[, target] to factors with the same levels
RF_predictions <- factor(RF_predictions, levels = c("Group 1", "Group 2"))
testData[, target] <- factor(testData[, target], levels = c("Group 1", "Group 2"))

# Create confusion matrix
conf_matrix <- confusionMatrix(RF_predictions, testData[, target])
print(conf_matrix)

# Calculate precision and recall manually
precision <- conf_matrix$byClass[1]
recall <- conf_matrix$byClass[2]
print(paste("Precision:", precision))
print(paste("Recall:", recall))

# Calculate ROC curve
RF_prob <- predict(model_RF, testData[, features], type = "prob")
roc_obj <- roc(testData[, target], RF_prob[, "Group 2"])
roc_plot <- plot(roc_obj, print.thres = "best", print.thres.best.method = "closest.topleft")
print(roc_plot)
```

#REPORT

The interesting findings from the analysis are as follows:

Classification Models: The code utilizes random forest and decision tree models for classification tasks. Both models are popular choices for solving classification problems in machine learning. It would be useful to assess the performance of these models on the given dataset to determine their effectiveness in predicting specific outcomes.
Feature Importance: Random forest and decision tree models can provide insights into feature importance. By examining the feature importances, it is possible to identify which variables contribute the most to the classification task. This information can be valuable in understanding the factors that influence data science salaries and identifying the most significant features for prediction.
Dataset Features: The dataset includes various features that could potentially impact data science salaries, such as work year, experience level, employment type, job title, remote ratio, and company size. Analyzing these features in conjunction with the target variable (salary) can help identify patterns and relationships that may exist within the data.
Currency Conversion: The dataset includes salary information in different currencies. The code performs currency conversion to USD, which allows for consistent analysis and comparison of salaries across different regions. This conversion step is crucial for ensuring accurate and meaningful insights from the data.
Overall, the analysis aims to predict data science salaries based on the provided dataset using classification models. By examining the feature importances and considering various factors, the code can provide insights into the key determinants of data science salaries and facilitate salary prediction for different job roles and locations.



#REFLECTION
Reflecting on the course as a whole, I have gained a deeper understanding of data science and its applications. Through the various tasks and projects, I have learned how to analyze and interpret data, build predictive models, and derive meaningful insights from complex datasets. The course has equipped me with valuable knowledge and skills in data preprocessing, feature engineering, and machine learning algorithms. I have also gained experience in working with real-world datasets, which has enhanced my ability to handle and manipulate data effectively. Furthermore, the course has broadened my perspective on data science, showing me its wide-ranging impact in diverse fields such as finance, healthcare, and marketing. I now appreciate the importance of data-driven decision-making and the role of data scientists in extracting actionable insights from data. Overall, the course has been instrumental in deepening my understanding of data science and empowering me with practical skills to tackle real-world data challenges.